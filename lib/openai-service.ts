import OpenAI from 'openai';

// Configuraci√≥n del cliente OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || 'tu_api_key_aqui',
});

// Configuraci√≥n de modelos y costos
const AI_CONFIG = {
  models: {
    'gpt-4o-mini': {
      name: 'GPT-4o Mini',
      input_cost_per_1m: 0.15,
      output_cost_per_1m: 0.60,
      max_tokens: 16384,
      recommended: 'Econ√≥mico y eficiente'
    },
    'gpt-4o': {
      name: 'GPT-4o',
      input_cost_per_1m: 2.50,
      output_cost_per_1m: 10.00,
      max_tokens: 8192,
      recommended: 'M√°xima calidad'
    }
  },
  
  // L√≠mites de seguridad
  safety_limits: {
    max_monthly_cost: parseFloat(process.env.OPENAI_COST_LIMIT_MONTHLY || '10.00'),
    max_tokens_per_request: parseInt(process.env.OPENAI_MAX_TOKENS || '2000'),
    temperature: parseFloat(process.env.OPENAI_TEMPERATURE || '0.3')
  }
};

// Sistema de prompts especializados para SEMHYS
const SEMHYS_PROMPTS = {
  system_engineer: `Eres un ingeniero especialista de SEMHYS, empresa l√≠der en sistemas hidr√°ulicos, automatizaci√≥n industrial y eficiencia energ√©tica.

ESPECIALIDADES:
- Bombas centr√≠fugas y sistemas de presi√≥n
- Automatizaci√≥n con PLCs y SCADA
- An√°lisis de eficiencia energ√©tica
- Mantenimiento predictivo
- Instrumentaci√≥n y control
- Sistemas RCI (Remote Control Intelligence)

ESTILO DE RESPUESTA:
- T√©cnico pero claro y directo
- Basado en la experiencia de SEMHYS
- Con datos espec√≠ficos y medibles
- Enfocado en soluciones pr√°cticas
- Incluye recomendaciones concretas

FORMATO:
- Usa emojis t√©cnicos relevantes (‚öôÔ∏èüîßüìäüí°‚ö°)
- Estructura con t√≠tulos claros
- Incluye par√°metros t√©cnicos espec√≠ficos
- Sugiere pr√≥ximos pasos cuando sea apropiado`,

  analysis_expert: `Eres el analista t√©cnico principal de SEMHYS. Tu funci√≥n es analizar documentos t√©cnicos y extraer insights valiosos.

CAPACIDADES:
- An√°lisis de rendimiento de equipos
- Interpretaci√≥n de datos de monitoreo
- Diagn√≥stico de problemas t√©cnicos
- Comparaci√≥n entre sistemas similares
- Identificaci√≥n de oportunidades de mejora

METODOLOG√çA:
- Siempre busca patrones y tendencias
- Relaciona informaci√≥n de diferentes fuentes
- Cuantifica beneficios y ahorros potenciales
- Identifica riesgos y puntos cr√≠ticos
- Propone soluciones basadas en evidencia`,

  research_assistant: `Eres el asistente de investigaci√≥n t√©cnica de SEMHYS. Ayudas a encontrar informaci√≥n espec√≠fica en la base de datos documental.

FUNCI√ìN:
- Interpretar consultas t√©cnicas complejas
- Relacionar informaci√≥n dispersa en m√∫ltiples documentos
- Generar res√∫menes ejecutivos
- Identificar documentos m√°s relevantes
- Sugerir b√∫squedas relacionadas

CRITERIOS DE RELEVANCIA:
- Proximidad t√©cnica al tema consultado
- Proyectos con caracter√≠sticas similares
- Equipos del mismo tipo o fabricante
- An√°lisis de rendimiento comparable
- Lecciones aprendidas aplicables`
};

// Funci√≥n para calcular costo estimado
function estimateCost(inputTokens: number, outputTokens: number, model: string): number {
  const modelConfig = AI_CONFIG.models[model as keyof typeof AI_CONFIG.models];
  if (!modelConfig) return 0;
  
  const inputCost = (inputTokens / 1000000) * modelConfig.input_cost_per_1m;
  const outputCost = (outputTokens / 1000000) * modelConfig.output_cost_per_1m;
  
  return inputCost + outputCost;
}

// Funci√≥n para contar tokens aproximadamente
function estimateTokens(text: string): number {
  // Estimaci√≥n aproximada: 1 token ‚âà 0.75 palabras en espa√±ol
  return Math.ceil(text.split(' ').length * 1.33);
}

// Funci√≥n principal de an√°lisis con IA
export async function analyzeWithAI(
  query: string, 
  searchResults: any[], 
  analysisType: string = 'research'
): Promise<{
  analysis: string;
  cost_estimate: number;
  tokens_used: {input: number, output: number};
  model_used: string;
  suggestions: string[];
  confidence_score: number;
}> {
  
  try {
    // Verificar que tenemos API key
    if (!process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY === 'tu_api_key_aqui') {
      return {
        analysis: `üîë **API Key de OpenAI requerida**\n\nPara activar el an√°lisis con IA:\n\n1. Obt√©n tu API Key en: https://platform.openai.com/api-keys\n2. Agr√©gala al archivo .env.local: OPENAI_API_KEY=tu_key_real\n3. Reinicia el servidor\n\nüí∞ **Costo estimado**: ~$0.001 por consulta con GPT-4o Mini\n\n‚ö° Mientras tanto, tienes b√∫squeda avanzada con Elasticsearch funcionando.`,
        cost_estimate: 0,
        tokens_used: {input: 0, output: 0},
        model_used: 'none',
        suggestions: [
          'Configura la API Key para activar an√°lisis con IA',
          'Usa la b√∫squeda b√°sica mientras tanto',
          'Considera GPT-4o Mini para costos m√≠nimos'
        ],
        confidence_score: 0
      };
    }

    // Preparar contexto de documentos
    const documentContext = searchResults.slice(0, 5).map(doc => 
      `**${doc.title}** (${doc.document_type})\n${doc.content_preview}\n---`
    ).join('\n');

    // Seleccionar prompt seg√∫n tipo de an√°lisis
    let systemPrompt = SEMHYS_PROMPTS.research_assistant;
    if (analysisType.includes('equipment') || analysisType.includes('equipos')) {
      systemPrompt = SEMHYS_PROMPTS.system_engineer;
    } else if (analysisType.includes('analysis') || analysisType.includes('rendimiento')) {
      systemPrompt = SEMHYS_PROMPTS.analysis_expert;
    }

    // Construir prompt de usuario
    const userPrompt = `CONSULTA T√âCNICA: "${query}"

DOCUMENTOS ENCONTRADOS:
${documentContext}

AN√ÅLISIS REQUERIDO:
Como experto de SEMHYS, analiza la informaci√≥n encontrada y proporciona:

1. üìä **Resumen Ejecutivo**: S√≠ntesis de los hallazgos m√°s relevantes
2. üîß **An√°lisis T√©cnico**: Interpretaci√≥n especializada de los datos
3. üí° **Insights Clave**: Patrones, tendencias y oportunidades identificadas
4. üéØ **Recomendaciones**: Acciones concretas basadas en la evidencia
5. üìà **Pr√≥ximos Pasos**: Sugerencias para profundizar la investigaci√≥n

ENFOQUE: ${analysisType === 'equipos' ? 'An√°lisis de equipos y componentes' : 
           analysisType === 'rendimiento' ? 'Optimizaci√≥n y eficiencia' : 
           'Investigaci√≥n t√©cnica integral'}

Total documentos en base: ${searchResults.length} encontrados para esta consulta.`;

    // Estimar tokens de entrada
    const inputTokens = estimateTokens(systemPrompt + userPrompt);
    
    // Verificar l√≠mites
    if (inputTokens > AI_CONFIG.safety_limits.max_tokens_per_request) {
      throw new Error(`Consulta muy extensa (${inputTokens} tokens). L√≠mite: ${AI_CONFIG.safety_limits.max_tokens_per_request}`);
    }

    // Llamada a OpenAI
    const model = process.env.OPENAI_MODEL || 'gpt-4o-mini';
    console.log(`ü§ñ Analizando con ${model}...`);
    
    const completion = await openai.chat.completions.create({
      model: model,
      messages: [
        {
          role: 'system',
          content: systemPrompt
        },
        {
          role: 'user', 
          content: userPrompt
        }
      ],
      max_tokens: Math.min(AI_CONFIG.safety_limits.max_tokens_per_request, 2000),
      temperature: AI_CONFIG.safety_limits.temperature,
      top_p: 0.9,
      frequency_penalty: 0.1,
      presence_penalty: 0.1
    });

    const analysis = completion.choices[0]?.message?.content || 'No se pudo generar an√°lisis';
    const outputTokens = estimateTokens(analysis);
    const estimatedCost = estimateCost(inputTokens, outputTokens, model);

    // Generar sugerencias basadas en el contexto
    const suggestions = [
      `Analizar proyectos similares con "${query.split(' ')[0]}"`,
      `Buscar especificaciones t√©cnicas relacionadas`,
      `Revisar mantenimiento preventivo para estos equipos`,
      `Comparar rendimiento con proyectos anteriores`
    ];

    // Calcular confianza basada en cantidad y relevancia de resultados
    const confidenceScore = Math.min(
      0.95, 
      (searchResults.length / 10) * 0.6 + 
      (searchResults.filter(r => r.relevance_level === 'high').length / searchResults.length) * 0.4
    );

    return {
      analysis,
      cost_estimate: estimatedCost,
      tokens_used: { input: inputTokens, output: outputTokens },
      model_used: model,
      suggestions,
      confidence_score: confidenceScore
    };

  } catch (error) {
    console.error('üö® Error en an√°lisis IA:', error);
    
    return {
      analysis: `‚ùå **Error en el an√°lisis con IA**\n\n${error instanceof Error ? error.message : 'Error desconocido'}\n\nüîç **B√∫squeda b√°sica disponible**: Los resultados de Elasticsearch est√°n funcionando correctamente.`,
      cost_estimate: 0,
      tokens_used: { input: 0, output: 0 },
      model_used: 'error',
      suggestions: [
        'Verifica la configuraci√≥n de la API Key',
        'Intenta con una consulta m√°s corta',
        'Usa la b√∫squeda b√°sica mientras se resuelve'
      ],
      confidence_score: 0
    };
  }
}

// Funci√≥n para obtener estad√≠sticas de uso
export async function getAIUsageStats(): Promise<{
  model_config: typeof AI_CONFIG.models;
  current_model: string;
  safety_limits: typeof AI_CONFIG.safety_limits;
  api_status: 'configured' | 'missing' | 'invalid';
}> {
  
  const apiStatus = !process.env.OPENAI_API_KEY 
    ? 'missing' 
    : process.env.OPENAI_API_KEY === 'tu_api_key_aqui' 
    ? 'missing'
    : 'configured';
  
  return {
    model_config: AI_CONFIG.models,
    current_model: process.env.OPENAI_MODEL || 'gpt-4o-mini',
    safety_limits: AI_CONFIG.safety_limits,
    api_status: apiStatus
  };
}

// Funci√≥n para validar API Key
export async function validateOpenAIKey(): Promise<boolean> {
  try {
    if (!process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY === 'tu_api_key_aqui') {
      return false;
    }
    
    await openai.models.list();
    return true;
  } catch (error) {
    console.error('‚ùå API Key inv√°lida:', error);
    return false;
  }
}